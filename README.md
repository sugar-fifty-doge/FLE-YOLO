# FLE-YOLO
FLE-YOLO : faster, lighter and more efficient strategy for autonomous tower crane detection 

# Abstract
The detection and automated tracking of crane hooks, by providing real-time position and status information, effectively prevent safety accidents caused by hook failures or improper operations. Given the complex environments in which crane hooks operate during tower crane operations, deploying large-scale target detection algorithms on edge devices poses challenges such as mismatched frame rates leading to image latency. This paper proposes a rapid, lightweight, and effective object detection algorithm named FLE-YOLO.Firstly, FasterNet is employed as the backbone for feature extraction, integrating the Triplet Attention mechanism to emphasize target information while ensuring network lightweight. Secondly, a Slim-neck module is introduced at the bottleneck layer, utilizing lightweight convolution network GSconv to simplify network structure while enhancing recognition effectiveness. Lastly, the Dyhead module in the head unifies multiple attention operations to improve feature fusion efficiency and enhance model robustness against small targets and complex backgrounds.Experiments conducted on the public datasets VOC2012 and COCO2017 validate the algorithm's lightweight nature. Experimental results using images of crane hooks under complex conditions demonstrate significant improvements over the original algorithm: computational complexity reduced to 18.3 FLOPs, detection speed increased to 102.041 frames per second, accuracy improved to 96.6% (+3.6 percentage points), and AP50 reached 95.9% (+3.1 percentage points). Finally, field tests at construction sites effectively achieve detection and tracking of hooks, thereby enhancing safety in tower crane operations.

# Datasets
The datasets can be loaded from https://github.com/sugar-fifty-doge/Tower-crane-dataset 
